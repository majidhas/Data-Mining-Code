{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "This jupyter notebook is optional for those who feel proficient on the use of pandas library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**pandas** arises from the need to have a specific library to analyze data that provides, in the simplest possible way, all the instruments for data processing, data extraction, and data manipulation.\n",
    "\n",
    "Pandas design is based on numpy\n",
    "\n",
    "\n",
    "Pandas documentation:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/io.html\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you do not have pandas installed, you will need to install it. Enter the following\r\n",
    "command:\r\n",
    "\r\n",
    "pip install pandas "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we  will cover:\n",
    "\n",
    "1. Series \n",
    "2. DataFrames\n",
    "4. GroupBy\n",
    "5. Merging, Joining and Concatenating\n",
    "6. Operations\n",
    "7. Data Input and Output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's get started"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "\"\"\"\r\n",
    "Every time you see pd and np, \r\n",
    "youâ€™ll make reference to an object or method referring to these two libraries\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "you can check the version using __version__\r\n",
    "\"\"\"\r\n",
    "pd.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Series\n",
    "\n",
    "\n",
    "The series is the object of the pandas library designed to represent one-dimensional data structures, similar to an array but with some additional features. Its internal structure is simple  and is composed of two arrays associated with each other. The main array holds the data (data of any NumPy type) to which each element is associated with a label, contained within the other array, called the index."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Series"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "To declare a series  call the Series() constructor and pass as an argument an array containing the values to be included in it.\r\n",
    "\"\"\"\r\n",
    "series1 = pd.Series([1,2,3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "series1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "you can name the series and give also labels to the index!\r\n",
    "it's like a numpy array with names! \r\n",
    "\r\n",
    "1. create a list with the index labels\r\n",
    "2. a list with the values\r\n",
    "3. and pass them as parameters to the Series constructor!\r\n",
    "\"\"\"\r\n",
    "labels = [\"a\",\"b\",\"c\"] \r\n",
    "mydata = [1,2,3]\r\n",
    "series2 = pd.Series(data=mydata, index=labels, name=\"my_series\") "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "series2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "you can define a new series by a dictinary too\r\n",
    "Note: A dictionary is a collection which is unordered, changeable and indexed. You can think of it as a map, mapping values to keys\r\n",
    "\"\"\"\r\n",
    "dict_ = {\"a\": 10, \"b\":20, \"c\":30} #\"a\" these are keys and the numbers are values.\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dict_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "create the series in the same way, this time pass as a parameter the dictionary that we created\r\n",
    "\"\"\"\r\n",
    "series3 = pd.Series(dict_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "As you can see from this example, the array of the index is filled with the keys while\r\n",
    "the data are filled with the corresponding values\r\n",
    "\"\"\"\r\n",
    "series3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "If you want to individually see the two arrays that make up this data structure, you\r\n",
    "can call the two attributes of the series as follows: \r\n",
    "\r\n",
    "index and values\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "print(\"series values: \", series3.values)\r\n",
    "print(\"series index: \", series3.index)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting elements from series"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "series2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Using the key:\r\n",
    "\r\n",
    "You can select individual elements as ordinary numpy arrays, specifying the key. \r\n",
    "Start counting from 0, for the 1st element\r\n",
    "\"\"\"\r\n",
    "series2[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Or label:\r\n",
    "\r\n",
    "or by specifing the label corresponding to the position of the index.\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "series2[\"b\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "For  mupltiple elements:\r\n",
    "In the same way you select multiple items in a numpy array, you can specify the following \r\n",
    "\"\"\"\r\n",
    "series2[0:2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#or:\r\n",
    "series2[[\"a\", \"b\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframes \n",
    "\n",
    "Unlike series, which have an index array containing labels associated with each\n",
    "element, the dataframe has two index arrays. The first index array, associated with\n",
    "the lines, has very similar functions to the index array in series. In fact, each label is\n",
    "associated with all the values in the row. The second array contains a series of labels,\n",
    "each associated with a particular column.\n",
    "A dataframe may also be understood as a dict of series, where the keys are the\n",
    "column names and the values are the series that will form the columns of the dataframe. All elements in each series are mapped according to an array of labels, called the index. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "We will create a dictionary with many keys, each key will have a list of elements\r\n",
    "\r\n",
    "Important note: A dictionary has unique keys. You can't have keys with the same value\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "data = {'color' : ['blue','green','yellow','red','white'],\r\n",
    " 'object' : ['ball','pen','pencil','paper','mug'],\r\n",
    " 'price' : [1.2,1.0,0.6,0.9,1.7]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Convert it into a dataframe!\r\n",
    "\"\"\"\r\n",
    "df = pd.DataFrame(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Notice that by default the keys of the dict become the DataFrame columns\r\n",
    "\"\"\"\r\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#you can make a selection of columns\r\n",
    "frame2 = pd.DataFrame(data, columns=['object','price'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frame2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "You can also assign labels to the index! this you can do by specifying the index parameter of the DataFrame constructor\r\n",
    "\"\"\"\r\n",
    "df = pd.DataFrame(data, index = [\"one\", \"two\", \"three\", \"four\", \"five\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Slicing and locating"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Pass the name of the column, and you'll get the column you want\r\n",
    "\"\"\"\r\n",
    "df[\"color\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "The result is a series object\r\n",
    "\r\n",
    "Check the type by the type()\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "type(df[\"color\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Another way to grab a column is by specifying the name of the column.\r\n",
    "\r\n",
    "The same as when using the bracket notation. Sometimes python might confuse it with a method and thus cause an error. \r\n",
    "So use the bracket notation to be on the safe side.  \r\n",
    "\r\n",
    "Note: if you type df. and tab you'll see all the different methods you can call for the specific object\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "df.color"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Selection of multiple columns\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "df[[\"object\", \"price\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    ".loc\r\n",
    "\r\n",
    "location based index\r\n",
    "\"\"\"\r\n",
    "df.loc[\"one\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    ".iloc\r\n",
    "\r\n",
    "index based location\r\n",
    "\"\"\"\r\n",
    "df.iloc[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" \r\n",
    "selecting subsets of rows and columns , using loc \r\n",
    "\"\"\"\r\n",
    "df.loc[\"one\",\"price\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "The same but using iloc\r\n",
    "\r\n",
    "In this case you need to specify the index\r\n",
    "\"\"\"\r\n",
    "df.iloc[0,2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Selecting a subset of the dataframe \r\n",
    "\r\n",
    "format df.loc[[rows], [columns]]\r\n",
    "\"\"\"\r\n",
    "df.loc[[\"one\",\"two\"], [\"color\", \"price\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "The same result using iloc\r\n",
    "\"\"\"\r\n",
    "df.iloc[[0,1], [0,2]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Similarly you can define a range and get the subset of a dataframe\r\n",
    "\"\"\"\r\n",
    "df.iloc[1:3,1:3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assigning values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Creating a new column in the dataframe called new. \r\n",
    "\r\n",
    "Just assign a new column with the desired name and give it the values that you want. \r\n",
    "\r\n",
    "Here is an example where the new column is the combination of color and object columns\r\n",
    "\"\"\"\r\n",
    "df[\"new\"] = df[\"color\"] + df[\"object\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Here the new column which is called new2 is the price column in the power of 2. This operation happens row wise\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "df[\"new2\"] = df[\"price\"] **2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "\r\n",
    "Let's now remove the columns that we created above. \r\n",
    "\r\n",
    "\r\n",
    "You can use .drop() to do that. As parameters pass the name or list of names that you want to delete and specify the axis. \r\n",
    "\r\n",
    "Note1: \r\n",
    "If axis=0, it will delete the rows with the given nane \r\n",
    "if axis=1, it will delete the columns with the given 'name'\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "df.drop([\"new\", \"new2\"], axis=1)\r\n",
    "print(df)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Note2:\r\n",
    "\r\n",
    "pandas requires you to type inplace=True if you want all these to stay in place. otherwise it's just going to display but it's not going to be saved\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "df.drop([\"new\", \"new2\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "\r\n",
    "Let's drop now the row with index label equal to three and just display the result\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "df.drop(\"three\", axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assign a series to a dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ser = pd.Series(np.arange(5), index=[\"one\", \"two\", \"three\", \"four\", \"five\"]) #Return evenly spaced values within a given interval.\r\n",
    "\r\n",
    "\r\n",
    "#Note that the index of the series and the index of the dataframe should much\r\n",
    "\r\n",
    "#assign it to the dataframe\r\n",
    "df['new'] = ser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Membership Values\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "You get a dataframe containing Boolean values, where True indicates values that\r\n",
    "meet the membership.\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "df.isin([1.0,'pen'])\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "If you pass the value returned as a condition, then youâ€™ll get a\r\n",
    "new dataframe containing only the values that satisfy the condition.\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "df[df.isin([1.0,'pen'])]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#another way to delete a column\r\n",
    "\r\n",
    "del df[\"new\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conditional selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\"\"\"\r\n",
    "Conditional selection using brackets notations:\r\n",
    "You can apply the filtering through the application of certain conditions.\r\n",
    "\r\n",
    "\r\n",
    "Let's check, where is the dataframe less that 1.2?\r\n",
    "Direct masking operations are interpreted row-wise and not column-wise\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "df[df[\"price\"]<1.2]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#multiple conditions, use parentheses!\r\n",
    "\r\n",
    "df[(df[\"price\"]<1.2) & (df[\"object\"]==\"pencil\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transposition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "An operation that you might need when youâ€™re dealing with tabular data structures is\r\n",
    "transposition (that is, columns become rows and rows become columns). pandas allows\r\n",
    "you to do this in a very simple way. You can get the transposition of the dataframe by\r\n",
    "adding the T attribute to its application.\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "df.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Return a random sample of items from an axis object\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "df.sample(n=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.sample(frac=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create intervals"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Bin values into discrete intervals\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df[\"price_bins\"] = pd.cut(x = df[\"price\"], bins=[0, 0.6, 1.0, 1.7], labels=[\"interval1\", \"interval2\", \"interval3\"])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set and reset index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "The index will become the first column of the dataframe\r\n",
    "\"\"\"\r\n",
    "df.reset_index(inplace=True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "You can now rename the new index that you created.\r\n",
    "Assign a new column with the desired index names\r\n",
    "set the column as the new index using .set_index()\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "index = [\"a\",\"b\",\"c\",\"d\",\"e\"]\r\n",
    "df[\"new_index\"] = index\r\n",
    "df.set_index(\"new_index\", inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-index\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Multi-index\r\n",
    "outside = [\"G1\", \"G1\", \"G1\", \"G2\", \"G2\", \"G2\"]\r\n",
    "inside = [1,2,3,1,2,3]\r\n",
    "hier_index = list(zip(outside,inside)) #list of tuple pairs\r\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index) #a customization of making a df, takes a list creates a multi-index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from numpy.random import randn\r\n",
    "df = pd.DataFrame(randn(6,2), hier_index, [\"A\", \"B\"])\r\n",
    "#constructing a multi-level index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#call data\r\n",
    "df.loc[\"G1\"]\r\n",
    "df.loc[\"G1\"].loc[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.index.names\r\n",
    "#pandas the second indeses don't have names\r\n",
    "#so you can d: \r\n",
    "df.index.names = [\"Groups\", \"Num\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.loc[\"G2\"].loc[2][\"B\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cross-section fo multi-level index\r\n",
    "# it has the ability to go inside a muli-level index\r\n",
    "df.xs(\"G1\")\r\n",
    "#you want all the values were inner index is 1\r\n",
    "df.xs(1,level=\"Num\") #it would be more complicated with loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GroupBy\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "\r\n",
    "Groupby allows you to group together rows based off if a column and perform an aggregate function on them\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "# Create a new dataframe\r\n",
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\r\n",
    "       'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\r\n",
    "       'Sales':[200,120,340,124,243,350]}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "\r\n",
    "#Use groupby\r\n",
    "\r\n",
    "Using only groupby it will return a groupby object that points out where it's stored in memory.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "data.groupby('Company')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "An essential piece of analysis of large data is efficient summarization: computing\r\n",
    "aggregations like sum(), mean(), median(), min(), and max(), in which a single number\r\n",
    "gives insight into the nature of a potentially large datase\r\n",
    "\r\n",
    "\r\n",
    "So after groupby, specify a summarization function!\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "byComp = data.groupby('Company').mean() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "byComp\r\n",
    "#returns only for sales because person is strings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "byComp = data.groupby('Company').sum().loc[\"FB\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "byComp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "byComp = data.groupby('Company').describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "byComp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging, Joining, Concatenating"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of the preceding routines worked on single arrays. Itâ€™s also possible to combine\n",
    "multiple arrays into one, and to conversely split a single array into multiple arrays.\n",
    "Weâ€™ll take a look at those operations here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Let's first create three dataframes\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\r\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\r\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\r\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\r\n",
    "                        index=[0, 1, 2, 3])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\r\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\r\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\r\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\r\n",
    "                         index=[4, 5, 6, 7]) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\r\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\r\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\r\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\r\n",
    "                        index=[8, 9, 10, 11])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concatenation\n",
    "\n",
    "Concatenation basically glues together DataFrames. Keep in mind that dimensions should match along the axis you are concatenating on. You can use **pd.concat** and pass in a list of DataFrames to concatenate together:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.concat([df1,df2,df3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "#concat uses by default axis=0 and concats along the columns. \r\n",
    "\r\n",
    "\r\n",
    "Let's now try axis=1. \r\n",
    "You can see missing values becauses the rows of the three dataframes do not match!\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Important!\r\n",
    "Make sure that you have info that lines up correctly when u join the axis\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "pd.concat([df1,df2,df3],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\r\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\r\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\r\n",
    "   \r\n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\r\n",
    "                          'C': ['C0', 'C1', 'C2', 'C3'],\r\n",
    "                          'D': ['D0', 'D1', 'D2', 'D3']})    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The **merge** function allows you to merge DataFrames together using a similar logic as merging SQL Tables together. For example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.merge(left,right,how='inner',on='key')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Joining\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\r\n",
    "                     'B': ['B0', 'B1', 'B2']},\r\n",
    "                      index=['K0', 'K1', 'K2']) \r\n",
    "\r\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\r\n",
    "                    'D': ['D0', 'D2', 'D3']},\r\n",
    "                      index=['K0', 'K2', 'K3'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#like merge, but keys are on index instead of a column\r\n",
    "left.join(right)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions by Row and Column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use your own definition of functions to make changes in a dataframe.\n",
    "The important point is that they operate on a one-dimensional\n",
    "array, giving a single number as a result. For example, you can define a lambda function\n",
    "that calculates the range covered by the elements in an array\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#lambda is an anonymous function\r\n",
    "f = lambda x: x.max() + x.min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " # The above lambda function is equivalent to this function\r\n",
    " def f(x):\r\n",
    "    return x.max() - x.min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\r\n",
    "    index=['red','blue','yellow','white'],\r\n",
    "    columns=['ball','pen','pencil','paper'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Using the apply() function, you can apply the f function just defined on the dataframe column wise\r\n",
    "frame.apply(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " #and of course row wise specifying axis=1\r\n",
    " frame.apply(f, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Input and Output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Let's now store this dataframe into a csv file\r\n",
    "frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "you can do that by calling the to_csv function and pass as a parameter the path where you want the new file to be stored at. \r\n",
    "If you don't specidy the path and just type the name of the file then it will be stored under your current working directory\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "frame.to_csv(\"frame.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Now, if you want to read a csv file you can use the read_csv\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "data = pd.read_csv(\"frame.csv\", index_col=0 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# End of notebook for pandas\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "4a3821e50dfd29f54393a38062d93a54d0c9d954cd67861638d013f261604981"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}