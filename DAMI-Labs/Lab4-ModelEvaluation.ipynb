{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 4: Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This lab contains various methods for evaluating the model created in the previous lab. So far, no automatic process has been performed to determine the optimal parameters. In this lab, you will learn how to perform a grid search to find good parameter settings and perform k-fold to ensure the model's generalizability."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contents\n",
    "- 4-1. Model evaluation methods in scikit-learn\n",
    "  - K-fold\n",
    "  - Grid search\n",
    "  - Nested k-fold\n",
    "  \n",
    "- 4-2. Manual implementation\n",
    "  - K-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4-1. Model evaluation methods in scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first validation method we will learn is the **k-fold cross-validation**. This method is quite simple but most widely used in practice. It divides the dataset in a (k-1):1 ratio and uses the right part ($\\frac{1}{k}$ of the dataset) as a **validation set**, while training the model on the other $\\frac{k-1}{k}$ part. We change the validation set k times and run this validation k times with different parts of the dataset to generalize the validation performance. \n",
    "\n",
    "\n",
    "Split the data set in a (k-1):1 ratio, use the right part as the validation set and train the model on the other part. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the libraries\n",
    "\n",
    "Basic libraries used throughout this lab session. The random seed is set to ensure the same results as the instructor's ones."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "RANDOM_SEED = 12345"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the dataset\n",
    "\n",
    "In this lab, we will use the same data as we used in the previous lab: **Connectionist Bench** from UCI Machine Learning Repository, which can be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data). We already located the dataset into **datasets** directory, so you can simply include it from there. This dataset has two classes: ***Mines***, ***Rocks*** with 60 attributes representing each data entity. More information can be found <a href=\"https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)\">here</a>. If you have downloaded the whole package of our labs, you will not have any problem of loading the file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first thing you always need to do is loading data and check it is correctly loaded. We will use pandas to load and manipulate it. Since there is no proper **head** for the table, you need to choose not to use the first row as a set of column names. You can refer to the previous lab to further check whether the dataset is correctly loaded."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.read_csv(\"datasets/sonar.all-data\", header=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will continue to use scikit-learn, in which we manage labels and data attributes separately. Let's separate the data labels from the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Divide the dataset into two parts: attributes (X) and labels (y)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = data.drop(60, axis=1)\r\n",
    "y = data.iloc[:, -1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next task was to split the dataset into training and test sets in the previous lab. However, we will no longer have the test set. Instead, we will split our dataset into two parts: training and validation sets. Here we use the validation set for further generalization of our model. However, suppose we want to use the validation set for the model creation process to determine optimal parameters (e.g., together with grid search). In that case, we may need to split our dataset into three parts, including the test set to get final performance measures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are not trying optimization in this stage, we will just divide our dataset into two parts using the **k-fold cross validation** method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### K-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikit-learn provides two types of k-fold methods: k-fold and stratified k-fold. As the name suggests, stratified k-folds preserve the proportions of labels when separating datasets. We will try both and see which one produces a better model for our dataset. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's try a normal **k-fold** method. The first step is the same as other scikit-learn functions: import the class from the library package and create an instance. You can find k-fold in the *model_selection* package."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import KFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will initialize our instance as we did before for classifiers. Here we need to specify the number of splits (n_splits). Let's set it to five."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initialize an KFold instance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(n_splits=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can put our dataset into the **split** method of our instance. It will automatically divide our dataset with a 4:1 ratio five times following the original order of the dataset. This method only returns the indices, so we need to use those indices to get the actual data points. If we want to shuffle the datasets, we need to predefine the option when we create the instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Use the split method to iterate different indices for each fold and print the dataset using the indices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for train_index, test_index in kf.split(X):\r\n",
    "    # CHECK THE ORDERS OF THE SPLIT TRAINING SET AND THE TEST SET\r\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's try the **stratified k-fold** method. You can also find it in the model_selection package. We will use the same number of splits (five)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initialize a StratifiedKFold instance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, we also need to give our original **y** value to the split method so that the algorithm knows the label distribution and keeps it in the split dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Use the split method to iterate different indices for each fold and print the dataset using the indices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for train_index, test_index in skf.split(X, y):\r\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use this index to get a partitioned validation set and a partitioned training set, but that is too much work because there are many manual implementations. Scikit-learn provides another option to automate the cross-validation process called **cross_val_score**. This method returns a list of all performance scores from k iterations (cross-validation score)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use this method, we need to go through the same model creation process we learned last time. Let's make a basic SVC classifier with the RBF kernel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initialize a SVC instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf = SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function uses **StratifiedKFold** inside, so you do not need to worry about the class distribution. If you want to use **KFold** instead of **StratifiedKFold**, you may create a **KFold** instance and put it as a parameter into the function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Return a list of cross validation scores by using cross_val_score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NORMAL CASE: StratifiedKFold is applied\r\n",
    "scores = cross_val_score(clf, X, y, cv=5) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Return a list of cross validation scores by using cross_val_score with a customized KFold saved as `kf`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SPECIAL CASE: Normal KFold is applied\r\n",
    "kf = KFold(n_splits=5)\r\n",
    "scores2 = cross_val_score(clf, X, y, cv=kf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default score is **accuracy**, but you can also display other scores, such as precision, recall, and the F1 score. Let's display the F1 score instead of accuracy. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Return a list of cross validation scores by using cross_val_score with a customized scoring option (f1_macro)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores3 = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(scores3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Grid search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the last exercise, we tried to increase the test accuracy by adding different parameter values. However, this is practically impossible because you cannot always wait for the model to finish training, and you cannot manually put in numerous parameter combinations. In this situation, **grid search** can be used to find the optimal parameter given a specific range of parameters. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It receives sets of parameters as a dictionary list (a list having dictionaries as its entities). Inside each dictionary, we specify the possible combination of parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Define a parameter grid running two different grid search rounds, where one contains C and kernal and the other one contains C, gamma, and kernel as options."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = [\r\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\r\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\r\n",
    " ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, as always, we need to create an instance with all the parameters we have."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Define a grid search instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search = GridSearchCV(clf, param_grid, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can directly fit this instance with our dataset. Since it will run cross-validation inside, we do not need to put any other split dataset, but just the entire dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Fit the search to our dataset (`X`, `y`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our first grid-search is done! You can find out the best score and the best estimator."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Return the best estimator by using the attribute best_estimator_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search.best_estimator_"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Return the best score by using the attribute best_score_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nested k-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nested k-fold is used to estimate optimal parameters, but we do not have enough data entities in our dataset to separate it into three parts (training, validation, and test). This method first runs k-fold to run grid-search and runs another k-fold to test the performance measure. Therefore, it must shuffle the dataset before running each k-fold since its strategy is to estimate parameters and test using a different portion of the same dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are going to use a default SVC classifier again!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initiate a SVC instance with the RBF kernel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf = SVC(kernel=\"rbf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basic idea of nested k-fold is to use one cross-validation to **create**, and the other cross-validation to **evaluate** the models and pick the best one. We can say that the second cross-validation works like a test set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We eventually need a loop, but let's learn about a basic structure first."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need to set two different k-fold cross-validation instances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initiate two KFold instances, with the same option."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_cv = KFold(n_splits=4, shuffle=True, random_state=RANDOM_SEED)\r\n",
    "eval_cv = KFold(n_splits=4, shuffle=True, random_state=RANDOM_SEED+1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we also need to set one grid-search instance with the first k-fold instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initiate one grid search instance with `model_cv` as an option for cross validation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=model_cv)\r\n",
    "search.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get the best model from our first cross-validation set and the parameter grid."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, this best score is not useful since it evaluates the same portion of the training dataset. Therefore, now we need to use our second cross-validation instance to get a more reasonable cross-validation score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Initiate one grid search instance with `eval_cv` as an option for cross validation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(cross_val_score(search.best_estimator_, X=X, y=y, cv=eval_cv))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "That is just one cycle. We need to run the process multiple times to get the best model by comparing multiple mean cross-validation scores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Complete the development of nested k-fold by using two cross validation strategies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores = []\r\n",
    "searches = []\r\n",
    "\r\n",
    "COUNT = 4\r\n",
    "\r\n",
    "for i in range(COUNT):\r\n",
    "\r\n",
    "    model_cv = KFold(n_splits=4, shuffle=True)\r\n",
    "    eval_cv = KFold(n_splits=4, shuffle=True)\r\n",
    "    \r\n",
    "    search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=model_cv)\r\n",
    "    search.fit(X, y)\r\n",
    "    searches.append(search)\r\n",
    "\r\n",
    "    scores.append(np.mean(cross_val_score(search.best_estimator_, X=X, y=y, cv=eval_cv)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can pick the maximum score from the score list we made."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_score_idx = np.argmax(scores)\r\n",
    "max_score_idx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get the trained model information (parameter setting) from the index we get."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "searches[max_score_idx].best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4-2. Manual implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we are going to implement k-fold. It is a straightforward algorithm having only three steps: 1) divide the data into k folds, 2) choose one of the chunks as one set and all the other chunks as another set, 3) repeat 1-2 k times."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will also try to make the same structure with the one in the scikit-learn library so that we can quickly test and compare!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class KFold_Manual():\r\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=RANDOM_SEED):\r\n",
    "        return\r\n",
    "        \r\n",
    "    def split(self, X):\r\n",
    "        return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The answer is as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class KFold_Manual():\r\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=RANDOM_SEED):\r\n",
    "        self.n_splits = n_splits\r\n",
    "        self.shuffle = shuffle\r\n",
    "        self.random_state = RANDOM_SEED\r\n",
    "\r\n",
    "    def split(self, X):\r\n",
    "        #extract the indices\r\n",
    "        indices = X.index.values\r\n",
    "        #shuffle\r\n",
    "        if self.shuffle == True:\r\n",
    "            indices = np.random.shuffle(indices, random_state = self.random_state)\r\n",
    "        \r\n",
    "        #split\r\n",
    "        split_indices = np.array_split(indices, self.n_splits)\r\n",
    "        \r\n",
    "        #index manipulation\r\n",
    "        results = []\r\n",
    "\r\n",
    "        for i in range(self.n_splits):\r\n",
    "            splits = [np.zeros(0), np.zeros(0)]\r\n",
    "\r\n",
    "            for idx, val in enumerate(split_indices):\r\n",
    "                if idx != i:\r\n",
    "                    splits[0] = np.concatenate((splits[0], val))\r\n",
    "                else:\r\n",
    "                    splits[1] = np.concatenate((splits[1], val))\r\n",
    "                \r\n",
    "            results.append(splits)\r\n",
    "\r\n",
    "        return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's copy and paste the code above and run it here!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold_Manual()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for train_index, test_index in kf.split(X):\r\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# END OF LAB 4"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}